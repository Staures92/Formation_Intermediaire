{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab11: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://editor.analyticsvidhya.com/uploads/30783expressanlytics.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Exercice-1&nbsp;:-Analyse-des-sentiments\" data-toc-modified-id=\"Exercice-1&nbsp;:-Analyse-des-sentiments-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Exercice 1&nbsp;: Analyse des sentiments</a></span></li><li><span><a href=\"#Exercice-2-:-Classification-des-sujets\" data-toc-modified-id=\"Exercice-2-:-Classification-des-sujets-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Exercice 2 : Classification des sujets</a></span></li><li><span><a href=\"#Exercice-3-:-Régularisation\" data-toc-modified-id=\"Exercice-3-:-Régularisation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Exercice 3 : Régularisation</a></span></li><li><span><a href=\"#Exercice-4&nbsp;:&nbsp;incorporations-de-Word-Embeddings\" data-toc-modified-id=\"Exercice-4&nbsp;:&nbsp;incorporations-de-Word-Embeddings-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Exercice 4&nbsp;:&nbsp;incorporations de Word Embeddings</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Auto-setup when running on Google Colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !pip install openml\n",
    "\n",
    "# General imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import openml as oml\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de commencer, lisez le didacticiel de cet lab [Deep Learning with Python](https://ml-course.github.io/master/labs/Lab%207%20-%20Tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercice 1 : Analyse des sentiments\n",
    "* Prenez l'ensemble de données IMDB de keras.datasets avec 10 000 mots et le fractionnement de test de train par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0: ? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you\n",
      "Review 5: ? begins better than it ends funny that the russian submarine crew ? all other actors it's like those scenes\n",
      "Review 10: ? french horror cinema has seen something of a revival over the last couple of years with great films such\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "# Download IMDB data with 10000 most frequent words\n",
    "word_index = imdb.get_word_index()\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "for i in [0,5,10]:\n",
    "    print(\"Review {}:\".format(i),' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[i]][0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Vectorisez les avis en utilisant le one-hot-encoding (voir [tutoriel](https://ml-course.github.io/master/labs/Lab%207%20-%20Tutorial) pour le code d'aide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Construisez un réseau de 2 couches _Dense_ avec 16 nœuds chacune et la fonction d'activation _ReLU_.\n",
    "* Utilisez l'entropie croisée comme fonction de perte, RMSprop comme optimiseur et la précision comme métrique d'évaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Tracez les courbes d'apprentissage, en utilisant les 10 000 premiers échantillons comme ensemble de validation et le reste comme ensemble de train.\n",
    "* Utilisez 20 époques et une taille de lot de 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Reentrainez le modèle, cette fois en utilisant un arrêt anticipé pour arrêter l'entraînement au moment optimal\n",
    "* Évaluer sur l'ensemble de test et signaler l'accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Essayez d'améliorer manuellement le score et expliquez ce que vous observez. Par exemple. vous pourriez:\n",
    "     - Essayez 3 couches cachées\n",
    "     - Passer à un taux d'apprentissage plus élevé (par exemple 0,4)\n",
    "     - Essayez un autre optimiseur (par exemple Adagrad)\n",
    "     - Utiliser plus ou moins d'unités cachées (par exemple 64)\n",
    "     - Activation de `tanh` au lieu de `ReLU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ajustez les résultats en effectuant une recherche sur grille des hyperparamètres les plus intéressants\n",
    "     * Réglez le taux d'apprentissage entre 0,001 et 1\n",
    "     * Ajustez le nombre d'époques entre 1 et 20\n",
    "     * Utilisez seulement 3 à 4 valeurs pour chacun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercice 2 : Classification des sujets\n",
    "* Prenez l'ensemble de données Reuters de keras.datasets avec 10 000 mots et le fractionnement de test de train par défaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News wire 0: ? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "News wire 5: ? the u s agriculture department estimated canada's 1986 87 wheat crop at 31 85 mln tonnes vs 31 85 mln tonnes last month it estimated 1985 86 output at 24 25 mln tonnes vs 24 25 mln last month canadian 1986 87 coarse grain production is projected at 27 62 mln tonnes vs 27 62 mln tonnes last month production in 1985 86 is estimated at 24 95 mln tonnes vs 24 95 mln last month canadian wheat exports in 1986 87 are forecast at 19 00 mln tonnes vs 18 00 mln tonnes last month exports in 1985 86 are estimated at 17 71 mln tonnes vs 17 72 mln last month reuter 3\n",
      "News wire 10: ? period ended december 31 shr profit 11 cts vs loss 24 cts net profit 224 271 vs loss 511 349 revs 7 258 688 vs 7 200 349 reuter 3\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "for i in [0,5,10]:\n",
    "    print(\"News wire {}:\".format(i),\n",
    "          ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[i]]))\n",
    "    # Note that our indices were offset by 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Vectoriser les données et les étiquettes en utilisant le one-hot-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Construisez un réseau avec 2 couches denses de 64 nœuds chacune\n",
    "* Faire des choix judicieux concernant les fonctions d'activation, de perte, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Prendre un ensemble de validation à partir des 1000 premiers points de l'ensemble de train\n",
    "* Ajuster le modèle avec 20 époques et une taille de batch de 512\n",
    "* Tracez les courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Créez un goulot d'étranglement d'information : reconstruisez le modèle, mais n'utilisez désormais que 4 unités cachées dans la deuxième couche. Évaluez le modèle. Est-ce qu'il fonctionne toujours bien ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : Régularisation\n",
    "    * Retournez à l'ensemble de données IMDB\n",
    "    * Rentrainez avec seulement 4 unités par couche\n",
    "    * Tracez les résultats. Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Utilisez à nouveau 16 nœuds cachés dans les couches, mais ajoutez maintenant une régularisation du poids. Utilisez la perte L2 avec alpha=0,001. Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Ajoutez une couche Dropout après chaque couche dense. Utilisez un taux de dropout de 0,5. Qu'observez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercice 4 : incorporations de Word Embeddings\n",
    "\n",
    "* Au lieu du OneHot encoding, utilisez word embedding d'une longueur de 300\n",
    "* Ajoutez uniquement une couche de sortie après la couche d'embedding.\n",
    "* Entraînez l'embedding du mieux que vous pouvez (cela prend du temps !)\n",
    " * Évaluez comme avant. Est-ce que ça fonctionne mieux ?\n",
    "* Importer un GloVe intégré pré-entraîné sur Wikipedia\n",
    " * Évaluez comme avant. Est-ce que ça fonctionne mieux ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
